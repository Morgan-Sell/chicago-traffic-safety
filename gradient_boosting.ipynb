{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "from src import ensemble_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. RD_NO\n",
      "1. CRASH_DATE\n",
      "2. POSTED_SPEED_LIMIT\n",
      "3. TRAFFIC_CONTROL_DEVICE\n",
      "4. DEVICE_CONDITION\n",
      "5. WEATHER_CONDITION\n",
      "6. LIGHTING_CONDITION\n",
      "7. FIRST_CRASH_TYPE\n",
      "8. TRAFFICWAY_TYPE\n",
      "9. LANE_CNT\n",
      "10. ALIGNMENT\n",
      "11. ROADWAY_SURFACE_COND\n",
      "12. ROAD_DEFECT\n",
      "13. CRASH_TYPE\n",
      "14. INTERSECTION_RELATED_I\n",
      "15. NOT_RIGHT_OF_WAY_I\n",
      "16. HIT_AND_RUN_I\n",
      "17. PRIM_CONTRIBUTORY_CAUSE\n",
      "18. SEC_CONTRIBUTORY_CAUSE\n",
      "19. STREET_NO\n",
      "20. STREET_DIRECTION\n",
      "21. STREET_NAME\n",
      "22. BEAT_OF_OCCURRENCE\n",
      "23. WORK_ZONE_I\n",
      "24. WORK_ZONE_TYPE\n",
      "25. WORKERS_PRESENT_I\n",
      "26. INJURIES_UNKNOWN\n",
      "27. CRASH_HOUR\n",
      "28. CRASH_DAY_OF_WEEK\n",
      "29. LATITUDE\n",
      "30. LONGITUDE\n",
      "31. LOCATION\n",
      "32. crash_date\n",
      "33. crash_year\n",
      "34. crash_month\n",
      "35. is_fatal_or_incap\n",
      "36. time_of_day\n",
      "37. is_weekend\n",
      "38. season\n",
      "39. is_cyclist\n",
      "40. is_pedestrian\n",
      "41. is_head_on\n",
      "42. is_parked\n",
      "43. is_using_cellphone\n",
      "44. has_disregarded_traffic_devices\n",
      "45. is_failed_to_yield_right_of_way\n",
      "46. is_reckless_driving\n",
      "47. is_sleet_snow\n",
      "48. is_rain\n",
      "49. is_clear_weather\n",
      "50. has_snow_ice\n",
      "51. is_dark_no_lighting\n",
      "52. has_stop_sign_or_traffic_light\n",
      "53. is_intersection\n",
      "54. is_non_functioning_device\n",
      "55. has_no_controls\n",
      "56. is_day\n",
      "57. is_evening\n",
      "58. is_morning\n",
      "59. is_night\n",
      "60. is_fall\n",
      "61. is_spring\n",
      "62. is_summer\n",
      "63. is_winter\n"
     ]
    }
   ],
   "source": [
    "accidents = pd.read_csv('data/accidents.csv', index_cGradientBoostingClassifiereature in enumerate(accidents.columns):\n",
    "    print('{}. {}'.format(idx, feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [2, 37] + list(range(39, 64))\n",
    "selected_features = list(accidents.columns[indices])\n",
    "\n",
    "X = accidents[selected_features]\n",
    "y = accidents['is_fatal_or_incap']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(sampling_strategy=0.75, random_state=3)\n",
    "#oversampler = SMOTE(sampling_strategy=0.5, random_state=3)\n",
    "\n",
    "X_over, y_over = oversampler.fit_resample(X_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 50, 100]\n",
    "learning_rates = [0.001, 0.01, 0.1, 1, 10]\n",
    "max_depth = [1, 2, 3]\n",
    "params_grid = dict(n_estimators=n_estimators,\n",
    "                   learning_rate=learning_rates,\n",
    "                   max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GradientBoostingClassifier(random_state=3)\n",
    "\n",
    "clf = GridSearchCV(gbt, params_grid, cv=5, verbose=0, scoring='recall')\n",
    "\n",
    "best_model = clf.fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal # of Estimators: ', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Optimal Learning Rate: ', best_model.best_estimator_.get_params()['learning_rate'])\n",
    "print('Max. Depth of Tree: ', best_model.best_estimator_.get_params()['max_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = \n",
    "learning_rate = \n",
    "max_depth = \n",
    "\n",
    "gbt = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=3)\n",
    "rf.fit(X_over, y_over)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "print('\\n')\n",
    "print('Recall (Scores FN): ', round(recall_score(y_test, y_pred), 4))\n",
    "print('Precision (Scores FP): ', round(precision_score(y_test, y_pred), 4))\n",
    "print('AUC Score: ', round(roc_auc_score(y_test, y_prob), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "sns.heatmap(cf_matrix, cmap='coolwarm', annot=True, annot_kws={'size': 20, 'fontweight':'bold'}, fmt='d',\n",
    "                 xticklabels=False, yticklabels=False);\n",
    "#plt.savefig('img/cf_matrix.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_utils.calculate_and_plot_permutation_importance(rf, X_over, y_over, 20, 3, (15,10), 16, X_train.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
