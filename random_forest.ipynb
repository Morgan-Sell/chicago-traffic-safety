{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "from src import ensemble_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents = pd.read_csv('data/accidents.csv', index_col=0)\n",
    "for idx, feature in enumerate(accidents.columns):\n",
    "    print('{}. {}'.format(idx, feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Features and Process Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [2, 38, 40, 41, 42, 43, 48, 50, 53, 56, 57, 60, 64, 65]\n",
    "selected_features = list(accidents.columns[indices])\n",
    "\n",
    "X = accidents[selected_features]\n",
    "y = accidents['is_fatal_or_incap']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(sampling_strategy=0.75, random_state=3)\n",
    "#oversampler = SMOTE(sampling_strategy=0.75, random_state=3)\n",
    "\n",
    "X_over, y_over = oversampler.fit_resample(X_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[1]\n",
    "\n",
    "n_estimators = [10, 50, 100]\n",
    "max_features = [2, int(np.sqrt(n_features)), n_features // 2, n_features]\n",
    "max_depth = [1, 2, 3]\n",
    "params_grid = dict(n_estimators=n_estimators,\n",
    "                   max_features=max_features,\n",
    "                   max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=3)\n",
    "\n",
    "clf = GridSearchCV(rf, params_grid, cv=5, verbose=0, scoring='recall')\n",
    "\n",
    "best_model = clf.fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal # of Estimators: ', best_model.best_estimator_.get_params()['n_estimators'])\n",
    "print('Optimal # of Features per Node: ', best_model.best_estimator_.get_params()['max_features'])\n",
    "print('Max. Depth of Tree: ', best_model.best_estimator_.get_params()['max_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10\n",
    "max_features = 3\n",
    "max_depth = 3\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, random_state=3)\n",
    "rf.fit(X_over, y_over)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cf_matrix)\n",
    "print('\\n')\n",
    "print('Recall (Scores FN): ', round(recall_score(y_test, y_pred), 4))\n",
    "print('Precision (Scores FP): ', round(precision_score(y_test, y_pred), 4))\n",
    "print('AUC Score: ', round(roc_auc_score(y_test, y_prob), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "sns.heatmap(cf_matrix, cmap='coolwarm', annot=True, annot_kws={'size': 20, 'fontweight':'bold'}, fmt='d',\n",
    "                 xticklabels=False, yticklabels=False);\n",
    "#plt.savefig('img/cf_matrix.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_utils.calculate_and_plot_permutation_importance(rf, X_over, y_over, 20, 3, (10,8), 16, X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IGNORE FOR NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sorted_permutation_importance_df(model, X, y, n_iterations, random_state, features):\n",
    "    '''\n",
    "    Inputs:\n",
    "    Enter a fitted tree-based model, e.g. Random Forest or Gradient Boost.\n",
    "    X and y can be the training set or a hold-out set, i.e., validation or test.\n",
    "    X and y must be dataframes.\n",
    "    \n",
    "    Return:\n",
    "    Returns a sorted dataframe comprised of each feature's importance for the number of selected iterations.\n",
    "    The dataframe is sorted by the features' medians.\n",
    "    '''\n",
    "    \n",
    "    results = permutation_importance(model, X, y, n_repeats=n_iterations,\n",
    "                                     random_state=random_state, n_jobs=-1)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['feature'] = features\n",
    "    df['mean_importance'] = results['importances_mean']\n",
    "    df['std_importance'] = results['importances_std']\n",
    "    df.sort_values(by='mean_importance', axis=0, ascending=False, inplace=True)\n",
    "    return df\n",
    "\n",
    "def plot_horizontal_permutation_importance_boxplot(df, figsize, max_features):\n",
    "    '''\n",
    "    df must be sorted.\n",
    "    max_features is a limit on the number of features displayed\n",
    "    '''\n",
    "    \n",
    "    df2 = df.iloc[2:, :].copy()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    sns.barplot(data=df2, x='mean_importance', y='feature', ax=ax, palette='mako_r')\n",
    "    ax.set_xlabel('Mean Importance')\n",
    "    ax.set_title('Permutation Importance', fontsize=18)\n",
    "    fig.tight_layout();\n",
    "    fig.savefig('img/perm_import_sub.png')\n",
    "\n",
    "\n",
    "def calculate_and_plot_permutation_importance(model, X, y, n_iterations, random_state, figsize, max_features, features):\n",
    "    '''\n",
    "    Inputs:\n",
    "    Enter a fitted tree-based model, e.g. Random Forest or Gradient Boost.\n",
    "    X and y can be the training set or a hold-out set, i.e., validation or test.\n",
    "    X and y must be dataframes.\n",
    "    max_features is the number of features to be displayed on the boxplot.\n",
    "    \n",
    "    Returns a horizontal box plot summarizing each feature's permutation importance.\n",
    "    '''\n",
    "    sorted_df = create_sorted_permutation_importance_df(model, X, y, n_iterations, random_state, features)\n",
    "    plot_horizontal_permutation_importance_boxplot(sorted_df, figsize, max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_and_plot_permutation_importance(rf, X_over, y_over, 20, 3, (12,10), 16, X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
